# DisT5 ğŸš¨ğŸ“‰
**A Text-to-Text Transformer Model for Disaster Event Classification and Understanding**

DisT5 is a specialized NLP model based on T5 (Text-to-Text Transfer Transformer), pre-trained and fine-tuned on disaster-related datasets. It is capable of learning to classify, understand, and respond to emergency and disaster-related text. This project involves both pretraining from scratch using span corruption and fine-tuning for sequence classification.

---

## ğŸ” Overview

The purpose of DisT5 is to assist in emergency and humanitarian response efforts by:
- Detecting and classifying disaster-related tweets or messages.
- Understanding the nature and impact of events.
- Improving situational awareness for first responders and analysts.

---

## ğŸ“ Project Structure

```

dist5/
â”‚
â”œâ”€â”€ t5\_pretrain.py            # Pretraining script for T5 using span corruption
â”œâ”€â”€ t5\_finetune.py            # Fine-tuning script on labeled disaster dataset
â”œâ”€â”€ data/                     # Folder for datasets (CSV files)
â”œâ”€â”€ models/                   # Pretrained and fine-tuned model checkpoints
â”œâ”€â”€ logs/                     # TensorBoard logs and training logs
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ requirements.txt          # List of dependencies

````

---

## ğŸ“¦ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
````

Main libraries:

* `transformers`
* `datasets`
* `pytorch-lightning`
* `torch`
* `huggingface_hub`
* `scikit-learn`
* `tensorboard`

---

## ğŸš€ Pretraining (Masked Span Corruption)

```bash
python t5_pretrain.py --file_path data/disaster_raw.csv --output_dir models/pretrained
```

* Uses unsupervised learning with span corruption (similar to T5 pretraining).
* Generates corrupted input-output pairs with `<extra_id_n>` sentinel tokens.

You can customize the span length, input/output lengths, and batch sizes in the script.

---

## ğŸ¯ Fine-tuning

```bash
python t5_finetune.py
```

* Uses Hugging Face Trainer for supervised sequence classification.
* Trained on a labeled disaster dataset (`kaikouraEarthquake`) with multiple class labels like:

  * `Irrelevant`, `Impact`, `Infrastructure_Damage`, `Volunteer_Support`, etc.

---

## ğŸ§ª Evaluation

After fine-tuning, the model is evaluated using:

* **Accuracy**
* **F1-Score (macro, micro, weighted)**
* **Cohenâ€™s Kappa**

Evaluation predictions and logs are saved to the output directory.

---

## ğŸ“Š TensorBoard

You can monitor training with:

```bash
tensorboard --logdir logs/
```

---

## ğŸ¤— Model Hub Integration

The fine-tuned model is automatically pushed to Hugging Face Hub:

â¡ï¸ [View Model on Hugging Face](https://huggingface.co/rizvi-rahil786/t5-small-kaikouraEarthquake)

---

## ğŸ“ˆ Results (Example)

```text
Accuracy: 84.5%
F1 Score (macro): 83.9%
Cohenâ€™s Kappa: 0.79
```

---

## âœï¸ Contributing

Pull requests and issues are welcome!

1. Fork the repository
2. Create a new branch (`git checkout -b feature-name`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature-name`)
5. Create a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License. See `LICENSE` for more details.

---

## ğŸ‘¤ Author

**Nishant Kumar**
[GitHub](https://github.com/Nishant0986) â€¢ [LinkedIn](https://linkedin.com/in/nishant-singh-a20296325/)

---

## ğŸ†˜ Acknowledgments

* Hugging Face Transformers and Datasets
* PyTorch Lightning
* [CrisisNLP Dataset](http://crisisnlp.qcri.org/)
* Open-source community

---

## â­ï¸ If you find this project useful, please consider giving it a star!

```

Would you like me to also generate a `requirements.txt` for the project?
```
